{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI 330: Homework 4: APIs on AWS\n",
    "\n",
    "\n",
    "## Due: Friday, February 9, 2018,  11:59:00pm\n",
    "\n",
    "### Submission instructions</font>\n",
    "After completing this homework, you will turn in two files via Canvas ->  Assignments -> HW 4:\n",
    "Your Notebook, named si330-hw4-YOUR_UNIQUE_NAME.ipynb and\n",
    "the HTML file, named si330-hw4-YOUR_UNIQUE_NAME.html.\n",
    "\n",
    "### Name:  YOUR NAME GOES HERE\n",
    "### Uniqname: YOUR UNIQNAME GOES HERE\n",
    "### People you worked with: [if you didn't work with anyone else write \"I worked by myself\" here].\n",
    "\n",
    "## Top-Level Goal\n",
    "To create a microservice that returns the counts of all bigrams in a text passage.\n",
    "\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "After completing this Lab, you should know how to:\n",
    "* create an AWS Lambda function that takes a string and returns the counts of all bigrams in that text\n",
    "* write an AWS API Gateway integration which allows both GET and POST requests to access an AWS Lambda\n",
    "* write documenation to the microservice that you've created\n",
    "\n",
    "### Note: See end of notebook for notes about going \"Above and Beyond\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8]],\n",
       "\n",
       "       [[ 9, 10, 11],\n",
       "        [12, 13, 14],\n",
       "        [15, 16, 17]],\n",
       "\n",
       "       [[18, 19, 20],\n",
       "        [21, 22, 23],\n",
       "        [24, 25, 26]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy \n",
    "n=numpy.arange(27)\n",
    "\n",
    "print (n)\n",
    "\n",
    "n.reshape(3,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline of Steps For Analysis\n",
    "Here's an overview of the steps that you'll need to do to complete this lab.\n",
    "2. Upload data to an S3 bucket\n",
    "1. Create an AWS Lambda function that normalizes, tokenizes, and creates and counts bigrams from text, both via a POST request with the text and via a GET request to a URL that returns the text (e.g. an S3 bucket)\n",
    "3. Create a python code block in this notebook to demonstrate the functionality of your microservice\n",
    "\n",
    "Each of these steps is detailed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Upload data to an S3 bucket\n",
    "To get ready to test the POST functionality of the code you generate in the next step, you should upload a text file that is **500 or fewer lines** to an S3 bucket.  See the description of CORS for an explanation of why we want to put the data in the same domain (amazonaws.com) as the Lambda.\n",
    "\n",
    "Follow the same approach that we used in the lab to upload a small text file to your S3 bucket, ensuring that the permissions are set to allow public access\n",
    "\n",
    "### <font color=\"magenta\">Q1: Enter the URL of your text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your S3 text file's URL here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create an AWS Lambda function that normalizes, tokenizes, and creates and counts bigrams from text\n",
    "\n",
    "Similar to what we did in the lab, you're going to create a microservice that consists of two parts: an AWS Lambda and an API Gateway.  You can use exactly the same technique that we did in the lab to get started.\n",
    "\n",
    "You will need to modify the code in the Lambda to handle two types of requests:\n",
    "1. A GET request with a queryStringParameter of url=http://some.url.goes.here/text.txt, which specifies the location of the text to be processed and\n",
    "2. A POST request with the text to be processed included as the \"text\" value in the body payload.\n",
    "\n",
    "### The following code block is a reasonable starting point for creating your Lambda.  Note that this code should not be run in this notebook but rather serve as the starting point for your work in the Lambda editor.\n",
    "\n",
    "**NOTE** Please see https://stackoverflow.com/questions/21844546/forming-bigrams-of-words-in-list-of-sentences-with-python for hints about how to create bigrams without NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PUT SOME DOCUMENTATION HERE\n",
    "\"\"\"\n",
    "import json\n",
    "import re\n",
    "from botocore.vendored import requests # This line has been added. \n",
    "# You'll need to figure out how to use this requests, \n",
    "# but it works the same way as the requests module (called using ```import requests```) in python.\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    method = event['httpMethod']\n",
    "    text = \"\"\n",
    "    d = {\"text\": \"\"}\n",
    "    # Handle GET method\n",
    "    if method == 'GET':\n",
    "        params = event['queryStringParameters']\n",
    "        if params:\n",
    "            url = ... # retrieve the text from the URL\n",
    "    if method == 'POST':\n",
    "        body = json.loads(event['body'])\n",
    "        if 'text' in body:\n",
    "            # do something \n",
    "    # normalize\n",
    "    # tokenize\n",
    "    # find bigrams\n",
    "    # NOTE: see https://stackoverflow.com/questions/21844546/forming-bigrams-of-words-in-list-of-sentences-with-python\n",
    "    #       for hints about how to create bigrams\n",
    "    # count bigrams\n",
    "    \n",
    "    # Note the strict format of the return dictionary\n",
    "    # It must contain these three elements, and the body\n",
    "    # must be a stringified JSON object (i.e. you have to call \n",
    "    # json.dumps on the JSON structure you're returning)\n",
    "    return { \n",
    "        \"statusCode\": 200,\n",
    "        \"headers\": {\"Content-Type\": \"application/json\"},\n",
    "        \"body\": json.dumps(d),\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q2a: Enter the URL of your Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your Lambda's URL here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q2b: Copy your final Lambda code into the following code block (but do not run it here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy your lambda code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Demonstrate the GET and POST functionality of your Lambda\n",
    "\n",
    "### <font color=\"magenta\">Q3: Create a code block that uses `requests` to demonstrate the functionality of your Lambda.  You can modify the template below or create your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "lambdaURL = 'https://xgrku9txqc.execute-api.us-east-1.amazonaws.com/prod/bigrammer' # change this URL\n",
    "textURL = 'https://s3.amazonaws.com/si330w18-YOURUNIQNAME/whatever.txt' # change this URL\n",
    "\n",
    "# Demonstrate the GET functionality\n",
    "response = requests.get(lambdaURL + '?url=' + textURL)\n",
    "bigrams = json.loads(response.text)\n",
    "print(bigrams) # you should make this print something nicer\n",
    "\n",
    "s3text = requests.get(textURL) # get the text from the bucket\n",
    "d = {\"text\": s3text}\n",
    "response = requests.post(lambdaURL, json = d)\n",
    "bigrams = json.loads(response.text)\n",
    "print(bigrams) # you should make this print something nicer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your notebook, download it as HTML and submit both the .ipynb and .html files to Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes about going \"Above and Beyond\"\n",
    "\n",
    "There are ample opportunities for extending this homework assignment.  You might, for example, decide to break the microservice into three separate ones (normalizing, tokenizing, and creating bigrams).  Alternatively, you might invest time into getting NLTK data into Lambda so you can use its functionality (see https://stackoverflow.com/questions/42394335/paths-in-aws-lambda-with-python-nltk).  Another interesting investigation might be to use the addition of a data file to an S3 bucket as a trigger to run the bigram analysis, perhaps writing the results to another (public) bucket.\n",
    "\n",
    "**IF YOU CHOOSE TO GO ABOVE AND BEYOND, YOU _MUST_ CHANGE THE FOLLOWING MARKDOWN BLOCK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above and Beyond\n",
    "\n",
    "Indicate here why you believe that your work should be considered \"above and beyond\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
